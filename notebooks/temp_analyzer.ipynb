{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71412299",
   "metadata": {},
   "outputs": [],
   "source": [
    "h# -*- coding: utf-8 -*-\n",
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     cell_metadata_filter: -all\n",
    "#     custom_cell_magics: kql\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: percent\n",
    "#       format_version: '1.3'\n",
    "#       jupytext_version: 1.11.2\n",
    "#   kernelspec:\n",
    "#     display_name: thermal_3.10\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ścieżka do pliku\n",
    "seq_file_name = '600_56n17_1mm_-161_09_29_59_808'\n",
    "# seq_file_name = '600_41n20_1_2mm_-161_08_03_50_784'\n",
    "csv_path = f'./frames_output/{seq_file_name}/temperature_stats.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246fcad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytaj dane\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f770e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc836071",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df['Frame'], df['AvgTemp'], label='Średnia temperatura')\n",
    "plt.plot(df['Frame'], df['WeldAvgTemp'], label='Temperatura spawu')\n",
    "plt.plot(df['Frame'], df['BottomAvgTemp'], label='Temperatura dolna')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Klatka')\n",
    "plt.ylabel('Temperatura [°C]')\n",
    "plt.title('Zmiany temperatury podczas spawania')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7769476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['FrameNumber'] = df['Frame'].apply(lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "\n",
    "# # I teraz zamiast 'Frame' użyj 'FrameNumber' jako X\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.plot(df['FrameNumber'], df['AvgTemp'], label='Średnia temperatura')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe413066",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Oblicz różnicę temperatury między kolejnymi klatkami\n",
    "df['TempDiff'] = df['AvgTemp'].diff()\n",
    "\n",
    "# Wykryj anomalie: różnica większa niż próg\n",
    "threshold = 10  # możesz dostroić\n",
    "anomalies = df[df['TempDiff'].abs() > threshold]\n",
    "\n",
    "print(\"Wykryte anomalie:\")\n",
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9707f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(df['Frame'], df['AvgTemp'], label='Średnia temperatura')\n",
    "plt.scatter(anomalies['Frame'], anomalies['AvgTemp'], color='red', label='Anomalie')\n",
    "\n",
    "# Ustawienia osi X\n",
    "step = 20\n",
    "plt.xticks(ticks=range(0, len(df), step), labels=df['Frame'][::step], rotation=90)\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Klatka')\n",
    "plt.ylabel('Temperatura [°C]')\n",
    "plt.title('Detekcja anomalii temperatury')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "image_folder = f'./frames_output/{seq_file_name}/preview_fixed/'\n",
    "\n",
    "for frame_name in anomalies['Frame']:\n",
    "    # Zamień nazwę pliku .tiff na .jpg (jeśli masz JPG-i)\n",
    "    frame_name_jpg = frame_name.replace('.tiff', '.jpg')\n",
    "    \n",
    "    # Pełna ścieżka do pliku\n",
    "    image_path = os.path.join(image_folder, frame_name_jpg)\n",
    "    \n",
    "    # Sprawdź czy plik istnieje\n",
    "    if os.path.exists(image_path):\n",
    "        # Wczytaj obraz\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        # Wyświetl obraz\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Anomalia: {frame_name_jpg}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Nie znaleziono pliku: {frame_name_jpg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42980196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Załaduj dane\n",
    "df = pd.read_csv(f\"./frames_output/{seq_file_name}/temperature_stats.csv\")\n",
    "\n",
    "# Policz zmiany pomiędzy klatkami\n",
    "df['AvgTempDiff'] = df['AvgTemp'].diff()\n",
    "df['WeldAvgTempDiff'] = df['WeldAvgTemp'].diff()\n",
    "df['BottomHotPxDiff'] = df['BottomHotPx'].diff()\n",
    "\n",
    "# --- Funkcja scoringu anomalii ---\n",
    "def calculate_anomaly_score(row, thresholds):\n",
    "    score = 0\n",
    "    \n",
    "    # Sprawdzanie poszczególnych warunków\n",
    "    if abs(row['AvgTempDiff']) > thresholds['AvgTempDiff']:\n",
    "        score += 1\n",
    "    if abs(row['WeldAvgTempDiff']) > thresholds['WeldAvgTempDiff']:\n",
    "        score += 1\n",
    "    if abs(row['BottomHotPxDiff']) > thresholds['BottomHotPxDiff']:\n",
    "        score += 1\n",
    "    if row['WeldStdTemp'] > thresholds['WeldStdTemp']:\n",
    "        score += 1\n",
    "    if row['BottomAvgTemp'] < thresholds['BottomAvgTempLow']:\n",
    "        score += 1\n",
    "        \n",
    "    return score\n",
    "\n",
    "# --- Definicja progów ---\n",
    "thresholds = {\n",
    "    'AvgTempDiff': 10,          # skok średniej temperatury >10°C\n",
    "    'WeldAvgTempDiff': 8,       # zmiana temperatury spoiny >8°C\n",
    "    'BottomHotPxDiff': 5,       # zmiana liczby gorących pikseli >5\n",
    "    'WeldStdTemp': 80,          # odchylenie temperatury spoiny >80°C\n",
    "    'BottomAvgTempLow': 300     # średnia dolna temperatura <300°C (podejrzenie gaśnięcia łuku)\n",
    "}\n",
    "\n",
    "# --- Zastosowanie scoringu ---\n",
    "df['AnomalyScore'] = df.apply(lambda row: calculate_anomaly_score(row, thresholds), axis=1)\n",
    "\n",
    "# --- Oznacz anomalie ---\n",
    "df['Anomaly'] = df['AnomalyScore'] >= 2  # uznajemy za anomalię jeśli score >= 2\n",
    "\n",
    "# --- Wypisz anomalne klatki ---\n",
    "anomalies = df[df['Anomaly']]\n",
    "\n",
    "print(f\"\\n🔎 Wykryto {len(anomalies)} anomalnych klatek.\")\n",
    "print(anomalies[['Frame', 'AvgTemp', 'WeldAvgTemp', 'BottomAvgTemp', 'BottomHotPx', 'AnomalyScore']])\n",
    "\n",
    "# --- (opcjonalnie) Zapisz anomalie do osobnego CSV ---\n",
    "anomalies.to_csv(f\"./frames_output/{seq_file_name}/anomalies_detected.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c168e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Załaduj dane z wykrytymi anomaliami\n",
    "# anomalies = pd.read_csv(\"./frames_output/625_38n18_1_2mm_-161_07_41_19_806/anomalies_detected.csv\")\n",
    "\n",
    "# # Folder z zapisanymi obrazkami podglądów\n",
    "# preview_fixed_dir = \"./frames_output/625_38n18_1_2mm_-161_07_41_19_806/preview_fixed/\"\n",
    "\n",
    "# # Przygotuj wykres\n",
    "# fig, axes = plt.subplots(nrows=len(anomalies), ncols=2, figsize=(10, len(anomalies) * 5))\n",
    "\n",
    "# # Upewnij się, że są odpowiednie wymiary wykresu\n",
    "# if len(anomalies) == 1:\n",
    "#     axes = [axes]\n",
    "\n",
    "# # Dla każdej wykrytej anomalii\n",
    "# for i, row in anomalies.iterrows():\n",
    "#     frame_name = row['Frame']\n",
    "    \n",
    "#     # Ścieżka do podglądu obrazu\n",
    "#     image_path = os.path.join(preview_fixed_dir, frame_name.replace(\".tiff\", \".jpg\"))\n",
    "    \n",
    "#     # Wczytaj obrazek\n",
    "#     img = cv2.imread(image_path)\n",
    "    \n",
    "#     # Konwertuj obrazek do RGB, bo OpenCV ładuje w BGR\n",
    "#     img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     # Statystyki anomalii\n",
    "#     stats = f\"AvgTemp: {row['AvgTemp']:.2f}°C\\n\" \\\n",
    "#             f\"WeldAvgTemp: {row['WeldAvgTemp']:.2f}°C\\n\" \\\n",
    "#             f\"BottomAvgTemp: {row['BottomAvgTemp']:.2f}°C\\n\" \\\n",
    "#             f\"BottomHotPx: {row['BottomHotPx']}\\n\" \\\n",
    "#             f\"Anomaly Score: {row['AnomalyScore']}\"\n",
    "    \n",
    "#     # Wyświetl obrazek i statystyki\n",
    "#     axes[i][0].imshow(img_rgb)\n",
    "#     axes[i][0].axis('off')\n",
    "#     axes[i][0].set_title(f\"Anomalna Klatka: {frame_name}\")\n",
    "    \n",
    "#     axes[i][1].text(0.5, 0.5, stats, fontsize=12, ha='center', va='center')\n",
    "#     axes[i][1].axis('off')\n",
    "\n",
    "# # Dopasuj wykresy\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33bd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konwersja kolumny Frame do sortowania\n",
    "df['FrameID'] = df['Frame'].str.extract(r'(\\d+)').astype(int)\n",
    "df = df.sort_values(by='FrameID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b081dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styl wykresów\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(15, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76581482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres: Średnia temperatura spoiny\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.lineplot(data=df, x='FrameID', y='WeldAvgTemp')\n",
    "plt.title(\"Średnia temperatura spoiny\")\n",
    "plt.xlabel(\"Klatka\")\n",
    "plt.ylabel(\"°C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c714df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres: Odchylenie standardowe (zmienność)\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.lineplot(data=df, x='FrameID', y='WeldStdTemp')\n",
    "plt.title(\"Odchylenie standardowe temperatury spoiny\")\n",
    "plt.xlabel(\"Klatka\")\n",
    "plt.ylabel(\"°C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres: Temperatura łuku\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.lineplot(data=df, x='FrameID', y='BottomAvgTemp')\n",
    "plt.title(\"Średnia temperatura łuku (dolna część)\")\n",
    "plt.xlabel(\"Klatka\")\n",
    "plt.ylabel(\"°C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca771d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres: Ilość gorących pikseli\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.lineplot(data=df, x='FrameID', y='BottomHotPx')\n",
    "plt.title(\"Liczba pikseli >500°C w dolnej części\")\n",
    "plt.xlabel(\"Klatka\")\n",
    "plt.ylabel(\"Liczba pikseli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffd4612",
   "metadata": {},
   "source": [
    "PYTORCH SHIIIIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e07a5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Wczytaj dane\n",
    "df = pd.read_csv(f\"./frames_output/{seq_file_name}/temperature_stats.csv\")\n",
    "\n",
    "# Wybierz kolumny numeryczne (bez 'Frame' i Min/MaxTemp jeśli nie są istotne)\n",
    "features = df[['AvgTemp', 'WeldAvgTemp', 'WeldStdTemp', 'BottomAvgTemp', 'MiddleAvgTemp']]\n",
    "\n",
    "# Normalizacja (bardzo ważne dla autoenkodera)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Zamiana na tensory\n",
    "X = torch.tensor(features_scaled, dtype=torch.float32)\n",
    "dataset = TensorDataset(X)\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddea9d8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "model = Autoencoder(input_dim=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d136c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in loader:\n",
    "        x_batch = batch[0]\n",
    "        output = model(x_batch)\n",
    "        loss = criterion(output, x_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23056cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przeanalizuj cały zbiór danych po treningu\n",
    "with torch.no_grad():\n",
    "    recon = model(X)\n",
    "    errors = torch.mean((recon - X) ** 2, dim=1)  # MSE per sample\n",
    "\n",
    "# Dodaj do DataFrame\n",
    "df['reconstruction_error'] = errors.numpy()\n",
    "\n",
    "# Przykład: oznacz anomalie gdy błąd > próg (np. 95 percentyl)\n",
    "threshold = df['reconstruction_error'].quantile(0.95)\n",
    "df['anomaly'] = df['reconstruction_error'] > threshold\n",
    "\n",
    "df[['Frame', 'reconstruction_error', 'anomaly']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalies = df[df['anomaly']]\n",
    "df_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['Frame'], df['reconstruction_error'], label='Reconstruction error', color='blue')\n",
    "plt.axhline(y=threshold, color='red', linestyle='--', label=f'Threshold = {threshold:.4f}')\n",
    "\n",
    "# Zaznaczenie anomalii\n",
    "anomalies = df[df['anomaly']]\n",
    "plt.scatter(anomalies['Frame'], anomalies['reconstruction_error'], color='orange', label='Anomaly', zorder=5)\n",
    "\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.title('Błąd rekonstrukcji w czasie + anomalie')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Ustawienia osi X\n",
    "step = 50\n",
    "plt.xticks(ticks=range(0, len(df), step), labels=df['Frame'][::step], rotation=90)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96480c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['anomaly'].value_counts().plot(kind='bar', color=['green', 'red'])\n",
    "plt.title('Liczba ramek normalnych vs. anomalnych')\n",
    "plt.xticks(ticks=[0, 1], labels=['Normalne', 'Anomalie'], rotation=0)\n",
    "plt.ylabel('Liczba ramek')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c25c1e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "plt.plot(df['Frame'], df['WeldAvgTemp'], label='WeldAvgTemp')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Ustawienia osi X\n",
    "step = 100\n",
    "plt.xticks(ticks=range(0, len(df), step), labels=df['Frame'][::step], rotation=90)\n",
    "\n",
    "\n",
    "plt.title('Temperatura średnia spoiny w czasie')\n",
    "plt.ylabel('Temperatura')\n",
    "plt.xlabel('Frame')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e371b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --- KONFIGURACJA ---\n",
    "IMAGE_DIR = f'frames_output/{seq_file_name}/preview_fixed'\n",
    "IMAGE_SIZE = (64, 64)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# --- PRZYGOTOWANIE DANYCH ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # konwersja do 1 kanału\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),  # skala 0–1\n",
    "])\n",
    "\n",
    "class ThermalDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.files = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.files[idx])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, os.path.basename(self.files[idx])\n",
    "\n",
    "dataset = ThermalDataset(IMAGE_DIR, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "# --- AUTOENCODER ---\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),  # 32x32\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),  # 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # 8x8\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),  # 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),  # 32x32\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, kernel_size=3, stride=2, padding=1, output_padding=1),  # 64x64\n",
    "            nn.Sigmoid(),  # wyjście w zakresie 0–1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "model = ConvAutoencoder().to(DEVICE)\n",
    "\n",
    "\n",
    "# --- TRENING ---\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch, _ in dataloader:\n",
    "        batch = batch.to(DEVICE)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "# --- DETEKCJA ANOMALII ---\n",
    "model.eval()\n",
    "reconstruction_errors = []\n",
    "filenames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, fname in DataLoader(dataset, batch_size=1, shuffle=False):\n",
    "        img = img.to(DEVICE)\n",
    "        recon = model(img)\n",
    "        loss = criterion(recon, img)\n",
    "        reconstruction_errors.append(loss.item())\n",
    "        filenames.append(fname[0])\n",
    "\n",
    "# --- WIZUALIZACJA ---\n",
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "is_anomaly = [e > threshold for e in reconstruction_errors]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(reconstruction_errors, label='Reconstruction error')\n",
    "plt.axhline(y=threshold, color='red', linestyle='--', label=f'Threshold ({threshold:.4f})')\n",
    "\n",
    "anomalies = [i for i, a in enumerate(is_anomaly) if a]\n",
    "plt.scatter(anomalies, [reconstruction_errors[i] for i in anomalies], color='orange', label='Anomalie')\n",
    "\n",
    "plt.xlabel('Obraz')\n",
    "plt.ylabel('Błąd rekonstrukcji')\n",
    "plt.title('Anomalie wykryte na podstawie rekonstrukcji autoencodera')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- PODGLĄD NAJWYŻSZYCH BŁĘDÓW ---\n",
    "print(\"Obrazy potencjalnie anomalne:\")\n",
    "for i in anomalies:\n",
    "    print(f\"{filenames[i]} - error = {reconstruction_errors[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e073ece4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lista szczegółów\n",
    "detailed_anomalies = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (img, fname) in enumerate(DataLoader(dataset, batch_size=1, shuffle=False)):\n",
    "        img = img.to(DEVICE)\n",
    "        recon = model(img)\n",
    "        mse_map = F.mse_loss(recon, img, reduction='none').squeeze().cpu().numpy()\n",
    "        total_error = mse_map.mean()\n",
    "\n",
    "        if total_error > threshold:\n",
    "            # Klasyfikacja typu anomalii (proste heurystyki)\n",
    "            max_region_error = mse_map[24:40, 24:40].mean()  # centralna część\n",
    "            outside_error = (mse_map.sum() - max_region_error * 16 * 16) / (64*64 - 256)\n",
    "\n",
    "            if max_region_error < 0.001:  # środek ciemny = brak łuku\n",
    "                anomaly_type = \"Brak łuku\"\n",
    "            elif max_region_error < outside_error * 1.2:  # środek nie jest gorętszy niż reszta\n",
    "                anomaly_type = \"Łuk przesunięty\"\n",
    "            else:\n",
    "                anomaly_type = \"Inna anomalia (np. artefakt/kształt)\"\n",
    "\n",
    "            detailed_anomalies.append({\n",
    "                \"filename\": fname[0],\n",
    "                \"error\": total_error,\n",
    "                \"type\": anomaly_type,\n",
    "                \"mse_map\": mse_map,\n",
    "                \"image\": img.squeeze().cpu().numpy(),\n",
    "                \"reconstruction\": recon.squeeze().cpu().numpy(),\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd59d34f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for item in detailed_anomalies[:5]:  # pokaż pierwsze 5\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    axs[0].imshow(item['image'], cmap='gray')\n",
    "    axs[0].set_title('Oryginalny obraz')\n",
    "    axs[1].imshow(item['reconstruction'], cmap='gray')\n",
    "    axs[1].set_title('Rekonstrukcja')\n",
    "    axs[2].imshow(item['mse_map'], cmap='hot')\n",
    "    axs[2].set_title(f'Mapa błędu\\n({item[\"type\"]})')\n",
    "    plt.suptitle(f\"{item['filename']} - {item['type']} - Error={item['error']:.4f}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e0255",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(item['type'] for item in detailed_anomalies)\n",
    "\n",
    "plt.bar(counts.keys(), counts.values(), color='orange')\n",
    "plt.title(\"Rozkład typów anomalii\")\n",
    "plt.ylabel(\"Liczba przypadków\")\n",
    "plt.xticks(rotation=15)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e679358",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --- KONFIGURACJA ---\n",
    "IMAGE_DIR = f'frames_output/{seq_file_name}/preview_fixed'\n",
    "ROI = (295, 410, 345, 480)  # lewy, górny, prawy, dolny\n",
    "IMAGE_SIZE = (64, 64)  # zmniejszamy region\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# --- PRZYGOTOWANIE DANYCH ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class ArcRegionDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.files = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.files[idx]).convert(\"L\")\n",
    "        img = img.crop(ROI)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, os.path.basename(self.files[idx])\n",
    "\n",
    "dataset = ArcRegionDataset(IMAGE_DIR, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "# --- AUTOENCODER ---\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),  # 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),  # 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # 4x4\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),  # 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),  # 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1),  # 32x32\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "model = ConvAutoencoder().to(DEVICE)\n",
    "\n",
    "\n",
    "# --- TRENING ---\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch, _ in dataloader:\n",
    "        batch = batch.to(DEVICE)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "# --- DETEKCJA ANOMALII ---\n",
    "model.eval()\n",
    "reconstruction_errors = []\n",
    "filenames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, fname in DataLoader(dataset, batch_size=1, shuffle=False):\n",
    "        img = img.to(DEVICE)\n",
    "        recon = model(img)\n",
    "        loss = criterion(recon, img)\n",
    "        reconstruction_errors.append(loss.item())\n",
    "        filenames.append(fname[0])\n",
    "\n",
    "# --- ANALIZA ---\n",
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "is_anomaly = [e > threshold for e in reconstruction_errors]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(reconstruction_errors, label='Reconstruction error')\n",
    "plt.axhline(y=threshold, color='red', linestyle='--', label=f'Threshold ({threshold:.4f})')\n",
    "\n",
    "anomalies = [i for i, a in enumerate(is_anomaly) if a]\n",
    "plt.scatter(anomalies, [reconstruction_errors[i] for i in anomalies], color='orange', label='Anomalie')\n",
    "\n",
    "plt.xlabel('Obraz')\n",
    "plt.ylabel('Błąd rekonstrukcji')\n",
    "plt.title('Anomalie w obszarze łuku')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Wykryte anomalie:\")\n",
    "for i in anomalies:\n",
    "    print(f\"{filenames[i]} — error = {reconstruction_errors[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824aad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --- KONFIGURACJA ---\n",
    "IMAGE_DIR = f'frames_output/{seq_file_name}/preview_fixed'\n",
    "# IMAGE_DIR = f'frames_output/{seq_file_name}/no_ignition'\n",
    "IMAGE_SIZE = (64, 64)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- TRANSFORMACJE ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# --- DANE Z 2 ROIs ---\n",
    "class ThermalDatasetMultiROI(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.files = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        self.transform = transform\n",
    "        self.roi_arc = (295, 410, 345, 480)   # ROI łuku\n",
    "        self.roi_weld = (270, 250, 370, 400)  # ROI spoiny\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.files[idx])\n",
    "        arc_crop = img.crop(self.roi_arc)\n",
    "        weld_crop = img.crop(self.roi_weld)\n",
    "        if self.transform:\n",
    "            arc_crop = self.transform(arc_crop)\n",
    "            weld_crop = self.transform(weld_crop)\n",
    "        return arc_crop, weld_crop, os.path.basename(self.files[idx])\n",
    "\n",
    "# --- AUTOENCODER ---\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# --- PRZYGOTOWANIE ---\n",
    "dataset = ThermalDatasetMultiROI(IMAGE_DIR, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model_arc = ConvAutoencoder().to(DEVICE)\n",
    "model_weld = ConvAutoencoder().to(DEVICE)\n",
    "optimizer_arc = optim.Adam(model_arc.parameters(), lr=0.001)\n",
    "optimizer_weld = optim.Adam(model_weld.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# --- TRENING ---\n",
    "for epoch in range(EPOCHS):\n",
    "    model_arc.train()\n",
    "    model_weld.train()\n",
    "    loss_arc_sum, loss_weld_sum = 0.0, 0.0\n",
    "\n",
    "    for arc, weld, _ in dataloader:\n",
    "        arc = arc.to(DEVICE)\n",
    "        weld = weld.to(DEVICE)\n",
    "\n",
    "        out_arc = model_arc(arc)\n",
    "        loss_arc = criterion(out_arc, arc)\n",
    "        optimizer_arc.zero_grad()\n",
    "        loss_arc.backward()\n",
    "        optimizer_arc.step()\n",
    "        loss_arc_sum += loss_arc.item()\n",
    "\n",
    "        out_weld = model_weld(weld)\n",
    "        loss_weld = criterion(out_weld, weld)\n",
    "        optimizer_weld.zero_grad()\n",
    "        loss_weld.backward()\n",
    "        optimizer_weld.step()\n",
    "        loss_weld_sum += loss_weld.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Arc Loss: {loss_arc_sum:.4f} | Weld Loss: {loss_weld_sum:.4f}\")\n",
    "\n",
    "# --- DETEKCJA ANOMALII ---\n",
    "model_arc.eval()\n",
    "model_weld.eval()\n",
    "errors_arc = []\n",
    "errors_weld = []\n",
    "filenames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for arc, weld, fname in DataLoader(dataset, batch_size=1, shuffle=False):\n",
    "        arc = arc.to(DEVICE)\n",
    "        weld = weld.to(DEVICE)\n",
    "\n",
    "        recon_arc = model_arc(arc)\n",
    "        recon_weld = model_weld(weld)\n",
    "\n",
    "        err_arc = criterion(recon_arc, arc).item()\n",
    "        err_weld = criterion(recon_weld, weld).item()\n",
    "\n",
    "        errors_arc.append(err_arc)\n",
    "        errors_weld.append(err_weld)\n",
    "        filenames.append(fname[0])\n",
    "\n",
    "# --- ANALIZA ---\n",
    "thresh_arc = np.percentile(errors_arc, 95)\n",
    "thresh_weld = np.percentile(errors_weld, 95)\n",
    "anomalies_arc = [i for i, e in enumerate(errors_arc) if e > thresh_arc]\n",
    "anomalies_weld = [i for i, e in enumerate(errors_weld) if e > thresh_weld]\n",
    "\n",
    "# --- WIZUALIZACJA ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(errors_arc, label='Arc Error')\n",
    "plt.axhline(y=thresh_arc, color='red', linestyle='--', label='Threshold')\n",
    "plt.scatter(anomalies_arc, [errors_arc[i] for i in anomalies_arc], color='orange', label='Anomalies')\n",
    "plt.title('Anomalie łuku')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(errors_weld, label='Weld Error')\n",
    "plt.axhline(y=thresh_weld, color='red', linestyle='--', label='Threshold')\n",
    "plt.scatter(anomalies_weld, [errors_weld[i] for i in anomalies_weld], color='orange', label='Anomalies')\n",
    "plt.title('Anomalie spoiny')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- WYDRUK ---\n",
    "print(\"Anomalie łuku:\")\n",
    "for i in anomalies_arc:\n",
    "    print(f\"{filenames[i]} - error = {errors_arc[i]:.4f}\")\n",
    "\n",
    "print(\"\\nAnomalie spoiny:\")\n",
    "for i in anomalies_weld:\n",
    "    print(f\"{filenames[i]} - error = {errors_weld[i]:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(original_image.squeeze().cpu(), cmap='gray')\n",
    "plt.title(\"Oryginał\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(reconstructed_image.squeeze().cpu(), cmap='gray')\n",
    "plt.title(\"Rekonstrukcja\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cea526",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_arc.state_dict(), \"autoencoder_arc_reference.pth\")\n",
    "torch.save(model_weld.state_dict(), \"autoencoder_weld_reference.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05cdbf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model_arc = ConvAutoencoder().to(DEVICE)\n",
    "model_weld = ConvAutoencoder().to(DEVICE)\n",
    "\n",
    "model_arc.load_state_dict(torch.load(\"autoencoder_arc_reference.pth\"))\n",
    "model_weld.load_state_dict(torch.load(\"autoencoder_weld_reference.pth\"))\n",
    "\n",
    "model_arc.eval()\n",
    "model_weld.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc64f9",
   "metadata": {},
   "source": [
    "INTERFACE LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e1461",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --- ŚCIEŻKI ---\n",
    "NEW_IMAGE_DIR = f'frames_output/{seq_file_name}/preview_fixed'  # zmień na swój katalog\n",
    "MODEL_ARC_PATH = 'autoencoder_arc_reference.pth'\n",
    "MODEL_WELD_PATH = 'autoencoder_weld_reference.pth'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "IMAGE_SIZE = (64, 64)\n",
    "\n",
    "# --- TRANSFORMACJE ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# --- STRUKTURA MODELU ---\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# --- ŁADOWANIE MODELÓW ---\n",
    "model_arc = ConvAutoencoder().to(DEVICE)\n",
    "model_arc.load_state_dict(torch.load(MODEL_ARC_PATH))\n",
    "model_arc.eval()\n",
    "\n",
    "model_weld = ConvAutoencoder().to(DEVICE)\n",
    "model_weld.load_state_dict(torch.load(MODEL_WELD_PATH))\n",
    "model_weld.eval()\n",
    "\n",
    "# --- DATASET Z ROIs ---\n",
    "class ThermalDatasetMultiROI(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.files = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        self.transform = transform\n",
    "        self.roi_arc = (295, 410, 345, 480)\n",
    "        self.roi_weld = (270, 250, 370, 400)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.files[idx])\n",
    "        arc_crop = img.crop(self.roi_arc)\n",
    "        weld_crop = img.crop(self.roi_weld)\n",
    "        if self.transform:\n",
    "            arc_crop = self.transform(arc_crop)\n",
    "            weld_crop = self.transform(weld_crop)\n",
    "        return arc_crop, weld_crop, os.path.basename(self.files[idx])\n",
    "\n",
    "# --- DANE I PRZETWARZANIE ---\n",
    "dataset = ThermalDatasetMultiROI(NEW_IMAGE_DIR, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "errors_arc, errors_weld, filenames = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for arc, weld, fname in dataloader:\n",
    "        arc = arc.to(DEVICE)\n",
    "        weld = weld.to(DEVICE)\n",
    "\n",
    "        recon_arc = model_arc(arc)\n",
    "        recon_weld = model_weld(weld)\n",
    "\n",
    "        err_arc = criterion(recon_arc, arc).item()\n",
    "        err_weld = criterion(recon_weld, weld).item()\n",
    "\n",
    "        errors_arc.append(err_arc)\n",
    "        errors_weld.append(err_weld)\n",
    "        filenames.append(fname[0])\n",
    "\n",
    "# --- PROGI I WYKRYWANIE ---\n",
    "threshold_arc = np.percentile(errors_arc, 95)\n",
    "threshold_weld = np.percentile(errors_weld, 95)\n",
    "\n",
    "anomalies_arc = [i for i, e in enumerate(errors_arc) if e > threshold_arc]\n",
    "anomalies_weld = [i for i, e in enumerate(errors_weld) if e > threshold_weld]\n",
    "\n",
    "# --- WIZUALIZACJA ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(errors_arc, label=\"Arc Error\")\n",
    "plt.axhline(threshold_arc, color='r', linestyle='--', label='Threshold')\n",
    "plt.scatter(anomalies_arc, [errors_arc[i] for i in anomalies_arc], color='orange', label='Anomalies')\n",
    "plt.title(\"Anomalie łuku\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(errors_weld, label=\"Weld Error\")\n",
    "plt.axhline(threshold_weld, color='r', linestyle='--', label='Threshold')\n",
    "plt.scatter(anomalies_weld, [errors_weld[i] for i in anomalies_weld], color='orange', label='Anomalies')\n",
    "plt.title(\"Anomalie spoiny\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- WYDRUK ---\n",
    "print(\"\\n[ANOMALIE ŁUKU]\")\n",
    "for i in anomalies_arc:\n",
    "    print(f\"{filenames[i]} - error = {errors_arc[i]:.4f}\")\n",
    "\n",
    "print(\"\\n[ANOMALIE SPOINY]\")\n",
    "for i in anomalies_weld:\n",
    "    print(f\"{filenames[i]} - error = {errors_weld[i]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "custom_cell_magics": "kql",
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "thermal_3.10",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
