{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71412299",
   "metadata": {},
   "outputs": [],
   "source": [
    "h# -*- coding: utf-8 -*-\n",
    "# ---\n",
    "# jupyter:\n",
    "#   jupytext:\n",
    "#     cell_metadata_filter: -all\n",
    "#     custom_cell_magics: kql\n",
    "#     text_representation:\n",
    "#       extension: .py\n",
    "#       format_name: percent\n",
    "#       format_version: '1.3'\n",
    "#       jupytext_version: 1.11.2\n",
    "#   kernelspec:\n",
    "#     display_name: thermal_3.10\n",
    "#     language: python\n",
    "#     name: python3\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3994d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ≈öcie≈ºka do pliku\n",
    "seq_file_name = '600_56n17_1mm_-161_09_29_59_808'\n",
    "# seq_file_name = '600_41n20_1_2mm_-161_08_03_50_784'\n",
    "csv_path = f'./frames_output/{seq_file_name}/temperature_stats.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246fcad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytaj dane\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f770e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc836071",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.plot(df['Frame'], df['AvgTemp'], label='≈örednia temperatura')\n",
    "plt.plot(df['Frame'], df['WeldAvgTemp'], label='Temperatura spawu')\n",
    "plt.plot(df['Frame'], df['BottomAvgTemp'], label='Temperatura dolna')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Klatka')\n",
    "plt.ylabel('Temperatura [¬∞C]')\n",
    "plt.title('Zmiany temperatury podczas spawania')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7769476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['FrameNumber'] = df['Frame'].apply(lambda x: int(x.split('_')[1].split('.')[0]))\n",
    "\n",
    "# # I teraz zamiast 'Frame' u≈ºyj 'FrameNumber' jako X\n",
    "# plt.figure(figsize=(20,10))\n",
    "# plt.plot(df['FrameNumber'], df['AvgTemp'], label='≈örednia temperatura')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe413066",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Oblicz r√≥≈ºnicƒô temperatury miƒôdzy kolejnymi klatkami\n",
    "df['TempDiff'] = df['AvgTemp'].diff()\n",
    "\n",
    "# Wykryj anomalie: r√≥≈ºnica wiƒôksza ni≈º pr√≥g\n",
    "threshold = 10  # mo≈ºesz dostroiƒá\n",
    "anomalies = df[df['TempDiff'].abs() > threshold]\n",
    "\n",
    "print(\"Wykryte anomalie:\")\n",
    "print(anomalies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9707f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(df['Frame'], df['AvgTemp'], label='≈örednia temperatura')\n",
    "plt.scatter(anomalies['Frame'], anomalies['AvgTemp'], color='red', label='Anomalie')\n",
    "\n",
    "# Ustawienia osi X\n",
    "step = 20\n",
    "plt.xticks(ticks=range(0, len(df), step), labels=df['Frame'][::step], rotation=90)\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Klatka')\n",
    "plt.ylabel('Temperatura [¬∞C]')\n",
    "plt.title('Detekcja anomalii temperatury')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "image_folder = f'./frames_output/{seq_file_name}/preview_fixed/'\n",
    "\n",
    "for frame_name in anomalies['Frame']:\n",
    "    # Zamie≈Ñ nazwƒô pliku .tiff na .jpg (je≈õli masz JPG-i)\n",
    "    frame_name_jpg = frame_name.replace('.tiff', '.jpg')\n",
    "    \n",
    "    # Pe≈Çna ≈õcie≈ºka do pliku\n",
    "    image_path = os.path.join(image_folder, frame_name_jpg)\n",
    "    \n",
    "    # Sprawd≈∫ czy plik istnieje\n",
    "    if os.path.exists(image_path):\n",
    "        # Wczytaj obraz\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        # Wy≈õwietl obraz\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Anomalia: {frame_name_jpg}')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Nie znaleziono pliku: {frame_name_jpg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42980196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Za≈Çaduj dane\n",
    "df = pd.read_csv(f\"./frames_output/{seq_file_name}/temperature_stats.csv\")\n",
    "\n",
    "# Policz zmiany pomiƒôdzy klatkami\n",
    "df['AvgTempDiff'] = df['AvgTemp'].diff()\n",
    "df['WeldAvgTempDiff'] = df['WeldAvgTemp'].diff()\n",
    "df['BottomHotPxDiff'] = df['BottomHotPx'].diff()\n",
    "\n",
    "# --- Funkcja scoringu anomalii ---\n",
    "def calculate_anomaly_score(row, thresholds):\n",
    "    score = 0\n",
    "    \n",
    "    # Sprawdzanie poszczeg√≥lnych warunk√≥w\n",
    "    if abs(row['AvgTempDiff']) > thresholds['AvgTempDiff']:\n",
    "        score += 1\n",
    "    if abs(row['WeldAvgTempDiff']) > thresholds['WeldAvgTempDiff']:\n",
    "        score += 1\n",
    "    if abs(row['BottomHotPxDiff']) > thresholds['BottomHotPxDiff']:\n",
    "        score += 1\n",
    "    if row['WeldStdTemp'] > thresholds['WeldStdTemp']:\n",
    "        score += 1\n",
    "    if row['BottomAvgTemp'] < thresholds['BottomAvgTempLow']:\n",
    "        score += 1\n",
    "        \n",
    "    return score\n",
    "\n",
    "# --- Definicja prog√≥w ---\n",
    "thresholds = {\n",
    "    'AvgTempDiff': 10,          # skok ≈õredniej temperatury >10¬∞C\n",
    "    'WeldAvgTempDiff': 8,       # zmiana temperatury spoiny >8¬∞C\n",
    "    'BottomHotPxDiff': 5,       # zmiana liczby gorƒÖcych pikseli >5\n",
    "    'WeldStdTemp': 80,          # odchylenie temperatury spoiny >80¬∞C\n",
    "    'BottomAvgTempLow': 300     # ≈õrednia dolna temperatura <300¬∞C (podejrzenie ga≈õniƒôcia ≈Çuku)\n",
    "}\n",
    "\n",
    "# --- Zastosowanie scoringu ---\n",
    "df['AnomalyScore'] = df.apply(lambda row: calculate_anomaly_score(row, thresholds), axis=1)\n",
    "\n",
    "# --- Oznacz anomalie ---\n",
    "df['Anomaly'] = df['AnomalyScore'] >= 2  # uznajemy za anomaliƒô je≈õli score >= 2\n",
    "\n",
    "# --- Wypisz anomalne klatki ---\n",
    "anomalies = df[df['Anomaly']]\n",
    "\n",
    "print(f\"\\nüîé Wykryto {len(anomalies)} anomalnych klatek.\")\n",
    "print(anomalies[['Frame', 'AvgTemp', 'WeldAvgTemp', 'BottomAvgTemp', 'BottomHotPx', 'AnomalyScore']])\n",
    "\n",
    "# --- (opcjonalnie) Zapisz anomalie do osobnego CSV ---\n",
    "anomalies.to_csv(f\"./frames_output/{seq_file_name}/anomalies_detected.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c168e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# import pandas as pd\n",
    "# import os\n",
    "\n",
    "# # Za≈Çaduj dane z wykrytymi anomaliami\n",
    "# anomalies = pd.read_csv(\"./frames_output/625_38n18_1_2mm_-161_07_41_19_806/anomalies_detected.csv\")\n",
    "\n",
    "# # Folder z zapisanymi obrazkami podglƒÖd√≥w\n",
    "# preview_fixed_dir = \"./frames_output/625_38n18_1_2mm_-161_07_41_19_806/preview_fixed/\"\n",
    "\n",
    "# # Przygotuj wykres\n",
    "# fig, axes = plt.subplots(nrows=len(anomalies), ncols=2, figsize=(10, len(anomalies) * 5))\n",
    "\n",
    "# # Upewnij siƒô, ≈ºe sƒÖ odpowiednie wymiary wykresu\n",
    "# if len(anomalies) == 1:\n",
    "#     axes = [axes]\n",
    "\n",
    "# # Dla ka≈ºdej wykrytej anomalii\n",
    "# for i, row in anomalies.iterrows():\n",
    "#     frame_name = row['Frame']\n",
    "    \n",
    "#     # ≈öcie≈ºka do podglƒÖdu obrazu\n",
    "#     image_path = os.path.join(preview_fixed_dir, frame_name.replace(\".tiff\", \".jpg\"))\n",
    "    \n",
    "#     # Wczytaj obrazek\n",
    "#     img = cv2.imread(image_path)\n",
    "    \n",
    "#     # Konwertuj obrazek do RGB, bo OpenCV ≈Çaduje w BGR\n",
    "#     img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     # Statystyki anomalii\n",
    "#     stats = f\"AvgTemp: {row['AvgTemp']:.2f}¬∞C\\n\" \\\n",
    "#             f\"WeldAvgTemp: {row['WeldAvgTemp']:.2f}¬∞C\\n\" \\\n",
    "#             f\"BottomAvgTemp: {row['BottomAvgTemp']:.2f}¬∞C\\n\" \\\n",
    "#             f\"BottomHotPx: {row['BottomHotPx']}\\n\" \\\n",
    "#             f\"Anomaly Score: {row['AnomalyScore']}\"\n",
    "    \n",
    "#     # Wy≈õwietl obrazek i statystyki\n",
    "#     axes[i][0].imshow(img_rgb)\n",
    "#     axes[i][0].axis('off')\n",
    "#     axes[i][0].set_title(f\"Anomalna Klatka: {frame_name}\")\n",
    "    \n",
    "#     axes[i][1].text(0.5, 0.5, stats, fontsize=12, ha='center', va='center')\n",
    "#     axes[i][1].axis('off')\n",
    "\n",
    "# # Dopasuj wykresy\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33bd7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konwersja kolumny Frame do sortowania\n",
    "df['FrameID'] = df['Frame'].str.extract(r'(\\d+)').astype(int)\n",
    "df = df.sort_values(by='FrameID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b081dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Styl wykres√≥w\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(15, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76581482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres: ≈örednia temperatura spoiny\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.lineplot(data=df, x='FrameID', y='WeldAvgTemp')\n",
    "plt.title(\"≈örednia temperatura spoiny\")\n",
    "plt.xlabel(\"Klatka\")\n",
    "plt.ylabel(\"¬∞C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c714df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres: Odchylenie standardowe (zmienno≈õƒá)\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.lineplot(data=df, x='FrameID', y='WeldStdTemp')\n",
    "plt.title(\"Odchylenie standardowe temperatury spoiny\")\n",
    "plt.xlabel(\"Klatka\")\n",
    "plt.ylabel(\"¬∞C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b429a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres: Temperatura ≈Çuku\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.lineplot(data=df, x='FrameID', y='BottomAvgTemp')\n",
    "plt.title(\"≈örednia temperatura ≈Çuku (dolna czƒô≈õƒá)\")\n",
    "plt.xlabel(\"Klatka\")\n",
    "plt.ylabel(\"¬∞C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca771d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres: Ilo≈õƒá gorƒÖcych pikseli\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.lineplot(data=df, x='FrameID', y='BottomHotPx')\n",
    "plt.title(\"Liczba pikseli >500¬∞C w dolnej czƒô≈õci\")\n",
    "plt.xlabel(\"Klatka\")\n",
    "plt.ylabel(\"Liczba pikseli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffd4612",
   "metadata": {},
   "source": [
    "PYTORCH SHIIIIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e07a5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Wczytaj dane\n",
    "df = pd.read_csv(f\"./frames_output/{seq_file_name}/temperature_stats.csv\")\n",
    "\n",
    "# Wybierz kolumny numeryczne (bez 'Frame' i Min/MaxTemp je≈õli nie sƒÖ istotne)\n",
    "features = df[['AvgTemp', 'WeldAvgTemp', 'WeldStdTemp', 'BottomAvgTemp', 'MiddleAvgTemp']]\n",
    "\n",
    "# Normalizacja (bardzo wa≈ºne dla autoenkodera)\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Zamiana na tensory\n",
    "X = torch.tensor(features_scaled, dtype=torch.float32)\n",
    "dataset = TensorDataset(X)\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddea9d8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "model = Autoencoder(input_dim=X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d136c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in loader:\n",
    "        x_batch = batch[0]\n",
    "        output = model(x_batch)\n",
    "        loss = criterion(output, x_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23056cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przeanalizuj ca≈Çy zbi√≥r danych po treningu\n",
    "with torch.no_grad():\n",
    "    recon = model(X)\n",
    "    errors = torch.mean((recon - X) ** 2, dim=1)  # MSE per sample\n",
    "\n",
    "# Dodaj do DataFrame\n",
    "df['reconstruction_error'] = errors.numpy()\n",
    "\n",
    "# Przyk≈Çad: oznacz anomalie gdy b≈ÇƒÖd > pr√≥g (np. 95 percentyl)\n",
    "threshold = df['reconstruction_error'].quantile(0.95)\n",
    "df['anomaly'] = df['reconstruction_error'] > threshold\n",
    "\n",
    "df[['Frame', 'reconstruction_error', 'anomaly']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae86c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalies = df[df['anomaly']]\n",
    "df_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a34fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df['Frame'], df['reconstruction_error'], label='Reconstruction error', color='blue')\n",
    "plt.axhline(y=threshold, color='red', linestyle='--', label=f'Threshold = {threshold:.4f}')\n",
    "\n",
    "# Zaznaczenie anomalii\n",
    "anomalies = df[df['anomaly']]\n",
    "plt.scatter(anomalies['Frame'], anomalies['reconstruction_error'], color='orange', label='Anomaly', zorder=5)\n",
    "\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.title('B≈ÇƒÖd rekonstrukcji w czasie + anomalie')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Ustawienia osi X\n",
    "step = 50\n",
    "plt.xticks(ticks=range(0, len(df), step), labels=df['Frame'][::step], rotation=90)\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96480c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['anomaly'].value_counts().plot(kind='bar', color=['green', 'red'])\n",
    "plt.title('Liczba ramek normalnych vs. anomalnych')\n",
    "plt.xticks(ticks=[0, 1], labels=['Normalne', 'Anomalie'], rotation=0)\n",
    "plt.ylabel('Liczba ramek')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c25c1e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "plt.plot(df['Frame'], df['WeldAvgTemp'], label='WeldAvgTemp')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Ustawienia osi X\n",
    "step = 100\n",
    "plt.xticks(ticks=range(0, len(df), step), labels=df['Frame'][::step], rotation=90)\n",
    "\n",
    "\n",
    "plt.title('Temperatura ≈õrednia spoiny w czasie')\n",
    "plt.ylabel('Temperatura')\n",
    "plt.xlabel('Frame')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63e371b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --- KONFIGURACJA ---\n",
    "IMAGE_DIR = f'frames_output/{seq_file_name}/preview_fixed'\n",
    "IMAGE_SIZE = (64, 64)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# --- PRZYGOTOWANIE DANYCH ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),  # konwersja do 1 kana≈Çu\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),  # skala 0‚Äì1\n",
    "])\n",
    "\n",
    "class ThermalDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.files = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.files[idx])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, os.path.basename(self.files[idx])\n",
    "\n",
    "dataset = ThermalDataset(IMAGE_DIR, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "# --- AUTOENCODER ---\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),  # 32x32\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),  # 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),  # 8x8\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),  # 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),  # 32x32\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, kernel_size=3, stride=2, padding=1, output_padding=1),  # 64x64\n",
    "            nn.Sigmoid(),  # wyj≈õcie w zakresie 0‚Äì1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "model = ConvAutoencoder().to(DEVICE)\n",
    "\n",
    "\n",
    "# --- TRENING ---\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch, _ in dataloader:\n",
    "        batch = batch.to(DEVICE)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "# --- DETEKCJA ANOMALII ---\n",
    "model.eval()\n",
    "reconstruction_errors = []\n",
    "filenames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, fname in DataLoader(dataset, batch_size=1, shuffle=False):\n",
    "        img = img.to(DEVICE)\n",
    "        recon = model(img)\n",
    "        loss = criterion(recon, img)\n",
    "        reconstruction_errors.append(loss.item())\n",
    "        filenames.append(fname[0])\n",
    "\n",
    "# --- WIZUALIZACJA ---\n",
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "is_anomaly = [e > threshold for e in reconstruction_errors]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(reconstruction_errors, label='Reconstruction error')\n",
    "plt.axhline(y=threshold, color='red', linestyle='--', label=f'Threshold ({threshold:.4f})')\n",
    "\n",
    "anomalies = [i for i, a in enumerate(is_anomaly) if a]\n",
    "plt.scatter(anomalies, [reconstruction_errors[i] for i in anomalies], color='orange', label='Anomalie')\n",
    "\n",
    "plt.xlabel('Obraz')\n",
    "plt.ylabel('B≈ÇƒÖd rekonstrukcji')\n",
    "plt.title('Anomalie wykryte na podstawie rekonstrukcji autoencodera')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- PODGLƒÑD NAJWY≈ªSZYCH B≈ÅƒòD√ìW ---\n",
    "print(\"Obrazy potencjalnie anomalne:\")\n",
    "for i in anomalies:\n",
    "    print(f\"{filenames[i]} - error = {reconstruction_errors[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e073ece4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lista szczeg√≥≈Ç√≥w\n",
    "detailed_anomalies = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (img, fname) in enumerate(DataLoader(dataset, batch_size=1, shuffle=False)):\n",
    "        img = img.to(DEVICE)\n",
    "        recon = model(img)\n",
    "        mse_map = F.mse_loss(recon, img, reduction='none').squeeze().cpu().numpy()\n",
    "        total_error = mse_map.mean()\n",
    "\n",
    "        if total_error > threshold:\n",
    "            # Klasyfikacja typu anomalii (proste heurystyki)\n",
    "            max_region_error = mse_map[24:40, 24:40].mean()  # centralna czƒô≈õƒá\n",
    "            outside_error = (mse_map.sum() - max_region_error * 16 * 16) / (64*64 - 256)\n",
    "\n",
    "            if max_region_error < 0.001:  # ≈õrodek ciemny = brak ≈Çuku\n",
    "                anomaly_type = \"Brak ≈Çuku\"\n",
    "            elif max_region_error < outside_error * 1.2:  # ≈õrodek nie jest gorƒôtszy ni≈º reszta\n",
    "                anomaly_type = \"≈Åuk przesuniƒôty\"\n",
    "            else:\n",
    "                anomaly_type = \"Inna anomalia (np. artefakt/kszta≈Çt)\"\n",
    "\n",
    "            detailed_anomalies.append({\n",
    "                \"filename\": fname[0],\n",
    "                \"error\": total_error,\n",
    "                \"type\": anomaly_type,\n",
    "                \"mse_map\": mse_map,\n",
    "                \"image\": img.squeeze().cpu().numpy(),\n",
    "                \"reconstruction\": recon.squeeze().cpu().numpy(),\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd59d34f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "for item in detailed_anomalies[:5]:  # poka≈º pierwsze 5\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    axs[0].imshow(item['image'], cmap='gray')\n",
    "    axs[0].set_title('Oryginalny obraz')\n",
    "    axs[1].imshow(item['reconstruction'], cmap='gray')\n",
    "    axs[1].set_title('Rekonstrukcja')\n",
    "    axs[2].imshow(item['mse_map'], cmap='hot')\n",
    "    axs[2].set_title(f'Mapa b≈Çƒôdu\\n({item[\"type\"]})')\n",
    "    plt.suptitle(f\"{item['filename']} - {item['type']} - Error={item['error']:.4f}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8e0255",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "counts = Counter(item['type'] for item in detailed_anomalies)\n",
    "\n",
    "plt.bar(counts.keys(), counts.values(), color='orange')\n",
    "plt.title(\"Rozk≈Çad typ√≥w anomalii\")\n",
    "plt.ylabel(\"Liczba przypadk√≥w\")\n",
    "plt.xticks(rotation=15)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e679358",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --- KONFIGURACJA ---\n",
    "IMAGE_DIR = f'frames_output/{seq_file_name}/preview_fixed'\n",
    "ROI = (295, 410, 345, 480)  # lewy, g√≥rny, prawy, dolny\n",
    "IMAGE_SIZE = (64, 64)  # zmniejszamy region\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "# --- PRZYGOTOWANIE DANYCH ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class ArcRegionDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.files = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.files[idx]).convert(\"L\")\n",
    "        img = img.crop(ROI)\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, os.path.basename(self.files[idx])\n",
    "\n",
    "dataset = ArcRegionDataset(IMAGE_DIR, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "# --- AUTOENCODER ---\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, 3, stride=2, padding=1),  # 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, 3, stride=2, padding=1),  # 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),  # 4x4\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),  # 8x8\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),  # 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1),  # 32x32\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "model = ConvAutoencoder().to(DEVICE)\n",
    "\n",
    "\n",
    "# --- TRENING ---\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch, _ in dataloader:\n",
    "        batch = batch.to(DEVICE)\n",
    "        output = model(batch)\n",
    "        loss = criterion(output, batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "# --- DETEKCJA ANOMALII ---\n",
    "model.eval()\n",
    "reconstruction_errors = []\n",
    "filenames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for img, fname in DataLoader(dataset, batch_size=1, shuffle=False):\n",
    "        img = img.to(DEVICE)\n",
    "        recon = model(img)\n",
    "        loss = criterion(recon, img)\n",
    "        reconstruction_errors.append(loss.item())\n",
    "        filenames.append(fname[0])\n",
    "\n",
    "# --- ANALIZA ---\n",
    "threshold = np.percentile(reconstruction_errors, 95)\n",
    "is_anomaly = [e > threshold for e in reconstruction_errors]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(reconstruction_errors, label='Reconstruction error')\n",
    "plt.axhline(y=threshold, color='red', linestyle='--', label=f'Threshold ({threshold:.4f})')\n",
    "\n",
    "anomalies = [i for i, a in enumerate(is_anomaly) if a]\n",
    "plt.scatter(anomalies, [reconstruction_errors[i] for i in anomalies], color='orange', label='Anomalie')\n",
    "\n",
    "plt.xlabel('Obraz')\n",
    "plt.ylabel('B≈ÇƒÖd rekonstrukcji')\n",
    "plt.title('Anomalie w obszarze ≈Çuku')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Wykryte anomalie:\")\n",
    "for i in anomalies:\n",
    "    print(f\"{filenames[i]} ‚Äî error = {reconstruction_errors[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824aad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --- KONFIGURACJA ---\n",
    "IMAGE_DIR = f'frames_output/{seq_file_name}/preview_fixed'\n",
    "# IMAGE_DIR = f'frames_output/{seq_file_name}/no_ignition'\n",
    "IMAGE_SIZE = (64, 64)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- TRANSFORMACJE ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# --- DANE Z 2 ROIs ---\n",
    "class ThermalDatasetMultiROI(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.files = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        self.transform = transform\n",
    "        self.roi_arc = (295, 410, 345, 480)   # ROI ≈Çuku\n",
    "        self.roi_weld = (270, 250, 370, 400)  # ROI spoiny\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.files[idx])\n",
    "        arc_crop = img.crop(self.roi_arc)\n",
    "        weld_crop = img.crop(self.roi_weld)\n",
    "        if self.transform:\n",
    "            arc_crop = self.transform(arc_crop)\n",
    "            weld_crop = self.transform(weld_crop)\n",
    "        return arc_crop, weld_crop, os.path.basename(self.files[idx])\n",
    "\n",
    "# --- AUTOENCODER ---\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# --- PRZYGOTOWANIE ---\n",
    "dataset = ThermalDatasetMultiROI(IMAGE_DIR, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model_arc = ConvAutoencoder().to(DEVICE)\n",
    "model_weld = ConvAutoencoder().to(DEVICE)\n",
    "optimizer_arc = optim.Adam(model_arc.parameters(), lr=0.001)\n",
    "optimizer_weld = optim.Adam(model_weld.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# --- TRENING ---\n",
    "for epoch in range(EPOCHS):\n",
    "    model_arc.train()\n",
    "    model_weld.train()\n",
    "    loss_arc_sum, loss_weld_sum = 0.0, 0.0\n",
    "\n",
    "    for arc, weld, _ in dataloader:\n",
    "        arc = arc.to(DEVICE)\n",
    "        weld = weld.to(DEVICE)\n",
    "\n",
    "        out_arc = model_arc(arc)\n",
    "        loss_arc = criterion(out_arc, arc)\n",
    "        optimizer_arc.zero_grad()\n",
    "        loss_arc.backward()\n",
    "        optimizer_arc.step()\n",
    "        loss_arc_sum += loss_arc.item()\n",
    "\n",
    "        out_weld = model_weld(weld)\n",
    "        loss_weld = criterion(out_weld, weld)\n",
    "        optimizer_weld.zero_grad()\n",
    "        loss_weld.backward()\n",
    "        optimizer_weld.step()\n",
    "        loss_weld_sum += loss_weld.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Arc Loss: {loss_arc_sum:.4f} | Weld Loss: {loss_weld_sum:.4f}\")\n",
    "\n",
    "# --- DETEKCJA ANOMALII ---\n",
    "model_arc.eval()\n",
    "model_weld.eval()\n",
    "errors_arc = []\n",
    "errors_weld = []\n",
    "filenames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for arc, weld, fname in DataLoader(dataset, batch_size=1, shuffle=False):\n",
    "        arc = arc.to(DEVICE)\n",
    "        weld = weld.to(DEVICE)\n",
    "\n",
    "        recon_arc = model_arc(arc)\n",
    "        recon_weld = model_weld(weld)\n",
    "\n",
    "        err_arc = criterion(recon_arc, arc).item()\n",
    "        err_weld = criterion(recon_weld, weld).item()\n",
    "\n",
    "        errors_arc.append(err_arc)\n",
    "        errors_weld.append(err_weld)\n",
    "        filenames.append(fname[0])\n",
    "\n",
    "# --- ANALIZA ---\n",
    "thresh_arc = np.percentile(errors_arc, 95)\n",
    "thresh_weld = np.percentile(errors_weld, 95)\n",
    "anomalies_arc = [i for i, e in enumerate(errors_arc) if e > thresh_arc]\n",
    "anomalies_weld = [i for i, e in enumerate(errors_weld) if e > thresh_weld]\n",
    "\n",
    "# --- WIZUALIZACJA ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(errors_arc, label='Arc Error')\n",
    "plt.axhline(y=thresh_arc, color='red', linestyle='--', label='Threshold')\n",
    "plt.scatter(anomalies_arc, [errors_arc[i] for i in anomalies_arc], color='orange', label='Anomalies')\n",
    "plt.title('Anomalie ≈Çuku')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(errors_weld, label='Weld Error')\n",
    "plt.axhline(y=thresh_weld, color='red', linestyle='--', label='Threshold')\n",
    "plt.scatter(anomalies_weld, [errors_weld[i] for i in anomalies_weld], color='orange', label='Anomalies')\n",
    "plt.title('Anomalie spoiny')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- WYDRUK ---\n",
    "print(\"Anomalie ≈Çuku:\")\n",
    "for i in anomalies_arc:\n",
    "    print(f\"{filenames[i]} - error = {errors_arc[i]:.4f}\")\n",
    "\n",
    "print(\"\\nAnomalie spoiny:\")\n",
    "for i in anomalies_weld:\n",
    "    print(f\"{filenames[i]} - error = {errors_weld[i]:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1,2,1)\n",
    "plt.imshow(original_image.squeeze().cpu(), cmap='gray')\n",
    "plt.title(\"Orygina≈Ç\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(reconstructed_image.squeeze().cpu(), cmap='gray')\n",
    "plt.title(\"Rekonstrukcja\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cea526",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_arc.state_dict(), \"autoencoder_arc_reference.pth\")\n",
    "torch.save(model_weld.state_dict(), \"autoencoder_weld_reference.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05cdbf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model_arc = ConvAutoencoder().to(DEVICE)\n",
    "model_weld = ConvAutoencoder().to(DEVICE)\n",
    "\n",
    "model_arc.load_state_dict(torch.load(\"autoencoder_arc_reference.pth\"))\n",
    "model_weld.load_state_dict(torch.load(\"autoencoder_weld_reference.pth\"))\n",
    "\n",
    "model_arc.eval()\n",
    "model_weld.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc64f9",
   "metadata": {},
   "source": [
    "INTERFACE LOADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2e1461",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --- ≈öCIE≈ªKI ---\n",
    "NEW_IMAGE_DIR = f'frames_output/{seq_file_name}/preview_fixed'  # zmie≈Ñ na sw√≥j katalog\n",
    "MODEL_ARC_PATH = 'autoencoder_arc_reference.pth'\n",
    "MODEL_WELD_PATH = 'autoencoder_weld_reference.pth'\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "IMAGE_SIZE = (64, 64)\n",
    "\n",
    "# --- TRANSFORMACJE ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# --- STRUKTURA MODELU ---\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# --- ≈ÅADOWANIE MODEL√ìW ---\n",
    "model_arc = ConvAutoencoder().to(DEVICE)\n",
    "model_arc.load_state_dict(torch.load(MODEL_ARC_PATH))\n",
    "model_arc.eval()\n",
    "\n",
    "model_weld = ConvAutoencoder().to(DEVICE)\n",
    "model_weld.load_state_dict(torch.load(MODEL_WELD_PATH))\n",
    "model_weld.eval()\n",
    "\n",
    "# --- DATASET Z ROIs ---\n",
    "class ThermalDatasetMultiROI(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.files = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        self.transform = transform\n",
    "        self.roi_arc = (295, 410, 345, 480)\n",
    "        self.roi_weld = (270, 250, 370, 400)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.files[idx])\n",
    "        arc_crop = img.crop(self.roi_arc)\n",
    "        weld_crop = img.crop(self.roi_weld)\n",
    "        if self.transform:\n",
    "            arc_crop = self.transform(arc_crop)\n",
    "            weld_crop = self.transform(weld_crop)\n",
    "        return arc_crop, weld_crop, os.path.basename(self.files[idx])\n",
    "\n",
    "# --- DANE I PRZETWARZANIE ---\n",
    "dataset = ThermalDatasetMultiROI(NEW_IMAGE_DIR, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "errors_arc, errors_weld, filenames = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for arc, weld, fname in dataloader:\n",
    "        arc = arc.to(DEVICE)\n",
    "        weld = weld.to(DEVICE)\n",
    "\n",
    "        recon_arc = model_arc(arc)\n",
    "        recon_weld = model_weld(weld)\n",
    "\n",
    "        err_arc = criterion(recon_arc, arc).item()\n",
    "        err_weld = criterion(recon_weld, weld).item()\n",
    "\n",
    "        errors_arc.append(err_arc)\n",
    "        errors_weld.append(err_weld)\n",
    "        filenames.append(fname[0])\n",
    "\n",
    "# --- PROGI I WYKRYWANIE ---\n",
    "threshold_arc = np.percentile(errors_arc, 95)\n",
    "threshold_weld = np.percentile(errors_weld, 95)\n",
    "\n",
    "anomalies_arc = [i for i, e in enumerate(errors_arc) if e > threshold_arc]\n",
    "anomalies_weld = [i for i, e in enumerate(errors_weld) if e > threshold_weld]\n",
    "\n",
    "# --- WIZUALIZACJA ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(errors_arc, label=\"Arc Error\")\n",
    "plt.axhline(threshold_arc, color='r', linestyle='--', label='Threshold')\n",
    "plt.scatter(anomalies_arc, [errors_arc[i] for i in anomalies_arc], color='orange', label='Anomalies')\n",
    "plt.title(\"Anomalie ≈Çuku\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(errors_weld, label=\"Weld Error\")\n",
    "plt.axhline(threshold_weld, color='r', linestyle='--', label='Threshold')\n",
    "plt.scatter(anomalies_weld, [errors_weld[i] for i in anomalies_weld], color='orange', label='Anomalies')\n",
    "plt.title(\"Anomalie spoiny\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- WYDRUK ---\n",
    "print(\"\\n[ANOMALIE ≈ÅUKU]\")\n",
    "for i in anomalies_arc:\n",
    "    print(f\"{filenames[i]} - error = {errors_arc[i]:.4f}\")\n",
    "\n",
    "print(\"\\n[ANOMALIE SPOINY]\")\n",
    "for i in anomalies_weld:\n",
    "    print(f\"{filenames[i]} - error = {errors_weld[i]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "custom_cell_magics": "kql",
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "thermal_3.10",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
