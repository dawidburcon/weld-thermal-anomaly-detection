{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ścieżka do pliku\n",
    "seq_file_name = '600_56n17_1mm_-161_09_29_59_808'\n",
    "# seq_file_name = '600_41n20_1_2mm_-161_08_03_50_784'\n",
    "csv_path = f'../frames_output/{seq_file_name}/temperature_stats.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --- KONFIGURACJA ---\n",
    "IMAGE_DIR = f'../frames_output/{seq_file_name}/preview_fixed'\n",
    "# IMAGE_DIR = f'frames_output/{seq_file_name}/no_ignition'\n",
    "IMAGE_SIZE = (64, 64)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 50\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- TRANSFORMACJE ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# --- DANE Z 2 ROIs ---\n",
    "class ThermalDatasetMultiROI(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.files = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        self.transform = transform\n",
    "        self.roi_arc = (295, 410, 345, 480)   # ROI łuku\n",
    "        self.roi_weld = (270, 250, 370, 400)  # ROI spoiny\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.files[idx])\n",
    "        arc_crop = img.crop(self.roi_arc)\n",
    "        weld_crop = img.crop(self.roi_weld)\n",
    "        if self.transform:\n",
    "            arc_crop = self.transform(arc_crop)\n",
    "            weld_crop = self.transform(weld_crop)\n",
    "        return arc_crop, weld_crop, os.path.basename(self.files[idx])\n",
    "\n",
    "# --- AUTOENCODER ---\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# --- PRZYGOTOWANIE ---\n",
    "dataset = ThermalDatasetMultiROI(IMAGE_DIR, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model_arc = ConvAutoencoder().to(DEVICE)\n",
    "model_weld = ConvAutoencoder().to(DEVICE)\n",
    "optimizer_arc = optim.Adam(model_arc.parameters(), lr=0.001)\n",
    "optimizer_weld = optim.Adam(model_weld.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# --- TRENING ---\n",
    "for epoch in range(EPOCHS):\n",
    "    model_arc.train()\n",
    "    model_weld.train()\n",
    "    loss_arc_sum, loss_weld_sum = 0.0, 0.0\n",
    "\n",
    "    for arc, weld, _ in dataloader:\n",
    "        arc = arc.to(DEVICE)\n",
    "        weld = weld.to(DEVICE)\n",
    "\n",
    "        out_arc = model_arc(arc)\n",
    "        loss_arc = criterion(out_arc, arc)\n",
    "        optimizer_arc.zero_grad()\n",
    "        loss_arc.backward()\n",
    "        optimizer_arc.step()\n",
    "        loss_arc_sum += loss_arc.item()\n",
    "\n",
    "        out_weld = model_weld(weld)\n",
    "        loss_weld = criterion(out_weld, weld)\n",
    "        optimizer_weld.zero_grad()\n",
    "        loss_weld.backward()\n",
    "        optimizer_weld.step()\n",
    "        loss_weld_sum += loss_weld.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Arc Loss: {loss_arc_sum:.4f} | Weld Loss: {loss_weld_sum:.4f}\")\n",
    "\n",
    "# --- DETEKCJA ANOMALII ---\n",
    "model_arc.eval()\n",
    "model_weld.eval()\n",
    "errors_arc = []\n",
    "errors_weld = []\n",
    "filenames = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for arc, weld, fname in DataLoader(dataset, batch_size=1, shuffle=False):\n",
    "        arc = arc.to(DEVICE)\n",
    "        weld = weld.to(DEVICE)\n",
    "\n",
    "        recon_arc = model_arc(arc)\n",
    "        recon_weld = model_weld(weld)\n",
    "\n",
    "        err_arc = criterion(recon_arc, arc).item()\n",
    "        err_weld = criterion(recon_weld, weld).item()\n",
    "\n",
    "        errors_arc.append(err_arc)\n",
    "        errors_weld.append(err_weld)\n",
    "        filenames.append(fname[0])\n",
    "\n",
    "# --- ANALIZA ---\n",
    "thresh_arc = np.percentile(errors_arc, 95)\n",
    "thresh_weld = np.percentile(errors_weld, 95)\n",
    "anomalies_arc = [i for i, e in enumerate(errors_arc) if e > thresh_arc]\n",
    "anomalies_weld = [i for i, e in enumerate(errors_weld) if e > thresh_weld]\n",
    "\n",
    "# --- WIZUALIZACJA ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(errors_arc, label='Arc Error')\n",
    "plt.axhline(y=thresh_arc, color='red', linestyle='--', label='Threshold')\n",
    "plt.scatter(anomalies_arc, [errors_arc[i] for i in anomalies_arc], color='orange', label='Anomalies')\n",
    "plt.title('Anomalie łuku')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(errors_weld, label='Weld Error')\n",
    "plt.axhline(y=thresh_weld, color='red', linestyle='--', label='Threshold')\n",
    "plt.scatter(anomalies_weld, [errors_weld[i] for i in anomalies_weld], color='orange', label='Anomalies')\n",
    "plt.title('Anomalie spoiny')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(model_arc.state_dict(), \"../models/autoencoder_arc_reference.pth\")\n",
    "torch.save(model_weld.state_dict(), \"../models/autoencoder_weld_reference.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from MSE to SSIM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Arc Loss: 3.7887 | Weld Loss: 2.9457\n",
      "Epoch 2/10 | Arc Loss: 1.1333 | Weld Loss: 0.3648\n",
      "Epoch 3/10 | Arc Loss: 0.3652 | Weld Loss: 0.1884\n",
      "Epoch 4/10 | Arc Loss: 0.2527 | Weld Loss: 0.1539\n",
      "Epoch 5/10 | Arc Loss: 0.2164 | Weld Loss: 0.1292\n",
      "Epoch 6/10 | Arc Loss: 0.1919 | Weld Loss: 0.1138\n",
      "Epoch 7/10 | Arc Loss: 0.1720 | Weld Loss: 0.1020\n",
      "Epoch 8/10 | Arc Loss: 0.1581 | Weld Loss: 0.0978\n",
      "Epoch 9/10 | Arc Loss: 0.1491 | Weld Loss: 0.0904\n",
      "Epoch 10/10 | Arc Loss: 0.1410 | Weld Loss: 0.0861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dburcon/.pyenv/versions/3.10.15/envs/thermal_3.10/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:70: FutureWarning: Importing `spectral_angle_mapper` from `torchmetrics.functional` was deprecated and will be removed in 2.0. Import `spectral_angle_mapper` from `torchmetrics.image` instead.\n",
      "  _future_warning(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 148\u001b[0m\n\u001b[1;32m    145\u001b[0m arc, _, _ \u001b[38;5;241m=\u001b[39m dataset[i]\n\u001b[1;32m    146\u001b[0m recon \u001b[38;5;241m=\u001b[39m model_arc(arc\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE))\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 148\u001b[0m diff \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43marc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(diff, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhot\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    150\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArc anomaly: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "from torchmetrics.functional import structural_similarity_index_measure as ssim\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --- KONFIGURACJA ---\n",
    "seq_file_name = '600_56n17_1mm_-161_09_29_59_808'\n",
    "IMAGE_DIR = f'../frames_output/{seq_file_name}/preview_fixed'\n",
    "IMAGE_SIZE = (64, 64)\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- TRANSFORMACJE ---\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# --- DANE Z 2 ROIs ---\n",
    "class ThermalDatasetMultiROI(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.files = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        self.transform = transform\n",
    "        self.roi_arc = (295, 410, 345, 480)   # ROI łuku\n",
    "        self.roi_weld = (270, 250, 370, 400)  # ROI spoiny\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.files[idx])\n",
    "        arc_crop = img.crop(self.roi_arc)\n",
    "        weld_crop = img.crop(self.roi_weld)\n",
    "        if self.transform:\n",
    "            arc_crop = self.transform(arc_crop)\n",
    "            weld_crop = self.transform(weld_crop)\n",
    "        return arc_crop, weld_crop, os.path.basename(self.files[idx])\n",
    "\n",
    "# --- AUTOENCODER ---\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "\n",
    "# --- PRZYGOTOWANIE ---\n",
    "dataset = ThermalDatasetMultiROI(IMAGE_DIR, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model_arc = ConvAutoencoder().to(DEVICE)\n",
    "model_weld = ConvAutoencoder().to(DEVICE)\n",
    "optimizer_arc = optim.Adam(model_arc.parameters(), lr=0.001)\n",
    "optimizer_weld = optim.Adam(model_weld.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# --- TRENING ---\n",
    "for epoch in range(EPOCHS):\n",
    "    model_arc.train()\n",
    "    model_weld.train()\n",
    "    loss_arc_sum, loss_weld_sum = 0.0, 0.0\n",
    "\n",
    "    for arc, weld, _ in dataloader:\n",
    "        arc = arc.to(DEVICE)\n",
    "        weld = weld.to(DEVICE)\n",
    "\n",
    "        out_arc = model_arc(arc)\n",
    "        loss_arc = criterion(out_arc, arc)\n",
    "        optimizer_arc.zero_grad()\n",
    "        loss_arc.backward()\n",
    "        optimizer_arc.step()\n",
    "        loss_arc_sum += loss_arc.item()\n",
    "\n",
    "        out_weld = model_weld(weld)\n",
    "        loss_weld = criterion(out_weld, weld)\n",
    "        optimizer_weld.zero_grad()\n",
    "        loss_weld.backward()\n",
    "        optimizer_weld.step()\n",
    "        loss_weld_sum += loss_weld.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} | Arc Loss: {loss_arc_sum:.4f} | Weld Loss: {loss_weld_sum:.4f}\")\n",
    "\n",
    "# --- DETEKCJA ANOMALII + ZAPIS ---\n",
    "model_arc.eval()\n",
    "model_weld.eval()\n",
    "errors_arc = []\n",
    "errors_weld = []\n",
    "filenames = []\n",
    "\n",
    "anomalia_path = './anomalie_output'\n",
    "os.makedirs(anomalia_path, exist_ok=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for arc, weld, fname in DataLoader(dataset, batch_size=1, shuffle=False):\n",
    "        arc = arc.to(DEVICE)\n",
    "        weld = weld.to(DEVICE)\n",
    "\n",
    "        recon_arc = model_arc(arc)\n",
    "        recon_weld = model_weld(weld)\n",
    "\n",
    "        err_arc = (1.0 - ssim(recon_arc, arc)).cpu().item()\n",
    "        err_weld = (1.0 - ssim(recon_weld, weld)).cpu().item()\n",
    "\n",
    "        errors_arc.append(err_arc)\n",
    "        errors_weld.append(err_weld)\n",
    "        filenames.append(fname[0])\n",
    "\n",
    "# --- ANALIZA ---\n",
    "thresh_arc = np.percentile(errors_arc, 95)\n",
    "thresh_weld = np.percentile(errors_weld, 95)\n",
    "anomalies_arc = [i for i, e in enumerate(errors_arc) if e > thresh_arc]\n",
    "anomalies_weld = [i for i, e in enumerate(errors_weld) if e > thresh_weld]\n",
    "\n",
    "# --- ZAPIS ANOMALII + HEATMAPY ---\n",
    "for i in anomalies_arc:\n",
    "    fname = filenames[i]\n",
    "    arc, _, _ = dataset[i]\n",
    "    recon = model_arc(arc.unsqueeze(0).to(DEVICE)).cpu().squeeze(0)\n",
    "\n",
    "    diff = torch.abs(recon - arc).squeeze().numpy()\n",
    "    plt.imshow(diff, cmap='hot')\n",
    "    plt.title(f\"Arc anomaly: {fname}\")\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(anomalia_path, f\"heatmap_arc_{fname}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    img = Image.open(os.path.join(IMAGE_DIR, fname))\n",
    "    img.save(os.path.join(anomalia_path, f\"anomaly_arc_{fname}\"))\n",
    "\n",
    "for i in anomalies_weld:\n",
    "    fname = filenames[i]\n",
    "    _, weld, _ = dataset[i]\n",
    "    recon = model_weld(weld.unsqueeze(0).to(DEVICE)).cpu().squeeze(0)\n",
    "\n",
    "    diff = torch.abs(recon - weld).squeeze().numpy()\n",
    "    plt.imshow(diff, cmap='hot')\n",
    "    plt.title(f\"Weld anomaly: {fname}\")\n",
    "    plt.colorbar()\n",
    "    plt.savefig(os.path.join(anomalia_path, f\"heatmap_weld_{fname}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    img = Image.open(os.path.join(IMAGE_DIR, fname))\n",
    "    img.save(os.path.join(anomalia_path, f\"anomaly_weld_{fname}\"))\n",
    "\n",
    "# --- WIZUALIZACJA ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(errors_arc, label='Arc Error')\n",
    "plt.axhline(y=thresh_arc, color='red', linestyle='--', label='Threshold')\n",
    "plt.scatter(anomalies_arc, [errors_arc[i] for i in anomalies_arc], color='orange', label='Anomalies')\n",
    "plt.title('Anomalie łuku')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(errors_weld, label='Weld Error')\n",
    "plt.axhline(y=thresh_weld, color='red', linestyle='--', label='Threshold')\n",
    "plt.scatter(anomalies_weld, [errors_weld[i] for i in anomalies_weld], color='orange', label='Anomalies')\n",
    "plt.title('Anomalie spoiny')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thermal_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
